{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6806c512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b1145",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975ab30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (AutoTokenizer, AutoModel, \n",
    "                          AutoModelForSequenceClassification, \n",
    "                          DataCollatorWithPadding, AdamW, get_scheduler,\n",
    "                          get_linear_schedule_with_warmup,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d626f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932c6336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Setting up seed value\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed_all(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36b31f29",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-fe0432ff59d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'toxic_distilBERT_multilabel.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6e80a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18616e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20614fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d27c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and encode sequences in the actual test set\n",
    "sub_tokens = tokenizer.batch_encode_plus(tweets[\"cleaned_tweets\"].tolist(),\n",
    "                                         max_length = 200,\n",
    "                                         pad_to_max_length=True,\n",
    "                                         truncation=True,\n",
    "                                         return_token_type_ids=False\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccca278",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f6b170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a57c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_seq = torch.tensor(sub_tokens['input_ids'])\n",
    "sub_mask = torch.tensor(sub_tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d21b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f642a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data = TensorDataset(sub_seq, sub_mask)\n",
    "print(sub_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4233ec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7ea34672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataLoader for validation set\n",
    "sub_dataloader = DataLoader(sub_data, \n",
    "                            batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef67dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4d0532",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4775cf73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c295c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a89e722a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = \"distilbert-base-uncased\"\n",
    "PATH = \"toxic_distilBERT_multilabel.pt\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels = 6)\n",
    "model.load_state_dict(torch.load(PATH, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed67d8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure how long the evaluation going to takes.\n",
    "t0 = time.time()\n",
    "\n",
    "for step, batch in enumerate(sub_dataloader):\n",
    "    # Progress update every 40 batches.\n",
    "    if step % 40 == 0 and not step == 0:\n",
    "        # Calculate elapsed time in minutes.\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        # Report progress.\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(sub_dataloader), elapsed))\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids, b_input_mask)\n",
    "        pred_probs = torch.sigmoid(outputs.logits)\n",
    "        if step == 0:\n",
    "            predictions = pred_probs.cpu().detach().numpy()\n",
    "        else:\n",
    "            predictions = np.append(predictions, pred_probs.cpu().detach().numpy(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9da888",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0da468b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "69e07d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(predictions, columns = categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e0775802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.025818</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.210384</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.003843</td>\n",
       "      <td>0.000946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.413834</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.006434</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.007631</td>\n",
       "      <td>0.000893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.071086</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       toxic  severe_toxic   obscene    threat    insult  identity_hate\n",
       "0   0.025818      0.000016  0.000893  0.000042  0.000251       0.000084\n",
       "1   0.210384      0.000217  0.003905  0.000472  0.003843       0.000946\n",
       "2   0.000191      0.000008  0.000099  0.000020  0.000053       0.000029\n",
       "3   0.413834      0.000315  0.006434  0.000615  0.007631       0.000893\n",
       "4   0.001207      0.000005  0.000062  0.000018  0.000074       0.000037\n",
       "..       ...           ...       ...       ...       ...            ...\n",
       "93  0.071086      0.000036  0.001254  0.000065  0.000678       0.000114\n",
       "94  0.000182      0.000008  0.000099  0.000022  0.000051       0.000025\n",
       "95  0.001478      0.000011  0.000211  0.000030  0.000077       0.000028\n",
       "96  0.000255      0.000006  0.000108  0.000015  0.000042       0.000021\n",
       "97  0.001927      0.000008  0.000209  0.000023  0.000092       0.000033\n",
       "\n",
       "[98 rows x 6 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aef4090f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040565053058659886"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic = sum(predictions_df['toxic'])/len(predictions_df['toxic'])\n",
    "toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b6d0fbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic 4.056505305865989\n",
      "severe_toxic 0.004277355670331658\n",
      "obscene 0.07400146001526416\n",
      "threat 0.03237981459464283\n",
      "insult 0.058088189618910276\n",
      "identity_hate 0.021685312323862324\n"
     ]
    }
   ],
   "source": [
    "for name in categories:\n",
    "    calc = sum(predictions_df[name])/len(predictions_df[name]) * 100\n",
    "    print(name, calc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf85ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
